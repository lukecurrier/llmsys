{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short complaint to The Boston Globe about the rat problem at Northeastern CS:\n",
      "\n",
      "To the Editor,\n",
      "\n",
      "I am writing to express my frustration with the persistent rat problem at Northeastern University's College of Computer and Information Science. Despite repeated complaints, the infestation continues to plague students and faculty, making it difficult to focus on academic pursuits. I believe the math department's proximity to the university's food storage facilities is a significant contributor to the problem, and I urge the university to take immediate action to address this issue. Until then, I fear for the health and well-being of the CS community.\n",
      "\n",
      "Sincerely, [Your Name]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "BASE_URL = \"https://nerc.guha-anderson.com/v1\"\n",
    "API_KEY = \"PLACEHOLDER\"\n",
    "\n",
    "client = OpenAI(base_url=BASE_URL, api_key=\"\")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    messages = [{ \n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Write short complaint to The Boston Globe about the rat problem at Northeastern CS. Blame the math department. No more than 4 sentences.\" \n",
    "    }],\n",
    "    model = \"llama3p1-8b-instruct\",\n",
    "    temperature=0)\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luke\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Luke\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Luke\\.cache\\huggingface\\hub\\datasets--nuprl--engineering-llm-systems. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 31601/31601 [00:00<00:00, 704643.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "flights = load_dataset(\"nuprl/engineering-llm-systems\", name=\"flights\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "class Flight:\n",
    "    def __init__(self, flight_id: int):\n",
    "        self.flight_info = flights[flight_id]\n",
    "\n",
    "def find_flights(origin: str, destination: str, date: datetime.date) -> List[Flight]:\n",
    "    formatted_date = date.strftime(\"%Y-%m-%d\")\n",
    "    return [Flight(flight[\"id\"]) for flight in flights if flight[\"origin\"] == origin and flight[\"destination\"] == destination and flight[\"date\"] == formatted_date]\n",
    "\n",
    "def book_flight(flight_id: int) -> Optional[int]:\n",
    "    if flights[flight_id][\"available_seats\"] > 0:\n",
    "        return flight_id\n",
    "    else: \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = \"BOS\" \n",
    "destination = \"LAX\"\n",
    "date = datetime.date(2023, 1, 1)\n",
    "[flight for flight in flights if flight[\"origin\"] == origin and flight[\"destination\"] == destination and flight[\"date\"] == date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def run_chat(api_key: str):\n",
    "    base_url = \"https://nerc.guha-anderson.com/v1\"\n",
    "    prompt_prefix = \"\"\"You are an AI travel agent. Talk to the user as helpfully and briefly as possible, \n",
    "    answering their questions when possible but politely denying any query unrelated to travel.\n",
    "    \n",
    "    User input:\"\"\"\n",
    "\n",
    "    client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "\n",
    "    while True: \n",
    "        user_input = input(\"User (blank to quit):\")\n",
    "\n",
    "        if user_input == \"\":\n",
    "            print(\"[]\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"User (blank to quit): \"+ user_input)\n",
    "\n",
    "        # chatbot logic here\n",
    "        resp = client.chat.completions.create(\n",
    "            messages = [{ \n",
    "                \"role\": \"user\", \"content\": prompt_prefix + user_input \n",
    "            }],\n",
    "            model = \"llama3p1-8b-instruct\",\n",
    "            temperature=0)\n",
    "        print(resp.choices[0].message.content)\n",
    "\n",
    "run_chat(api_key = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
